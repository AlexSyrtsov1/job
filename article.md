# Применение рекуррентной модели нейросетей в прогнозировании SINR.

## Аннотация

Одной из важных задач в области беспроводных сетей является прогнозирование уровня сигнала к интерференции и шуму (SINR), который влияет на качество связи и производительность сети. 
В данной работе рассматривается возможность использования рекуррентной нейронной сети в качестве регрессора для оценки качества прогнозирования SINR.

## Задача

Основная задача проводимого исследования в предсказании по $n$ последовательным значениям SINR на оборудовании пользователя значения SINR на следующих $(n+i)$-м временных такте с использованием аппарата рекуррентной нейронной сети.

## Общее описание модели

В качестве модели рассматривается рекуррентная нейронная Long-Short Term Memory (LSTM) сеть. В отличие от классических алгоритмов с прямым ходом вычислений, рекуррентные нейросети принимают данные не единожды в виде отдельных параметров, а неоднократно в виде последовательного набора значений одного или нескольких параметров, имитируя механизм запоминания информации, что подходит для составления прогнозов по временным рядам. Также, немаловажное преимущество в способности предиктора предоставлять результат прогнозирования в виде схожего по длине с исходными данными временного ряда, нежели одного числового значения, что позволяет точнее анализировать динамику отслеживаемого параметра или набора параметров.

Дополнительными преимуществами LSTM-нейросети можно выделить распространённость модели, обширная база исследований самой модели и её применения, а также способность к запоминанию двух динамических состояний: кратковременного и долговременного.

## Математическая модель

LSTM можно представить в виде цепи, где каждое звено состоит из трёх ключевых компонентов:
- входной блок;
- блок забывания;
- выходной блок;

Через эти блоки проходят два потока: долгосрочное и краткосрочное состояния сети. Первое хранит некоторые ключевые данные, которые потенциально могут пригодиться нейросети для прогнозирования, а второе (краткосрочное) мы используем в качестве основного потока, который будет принимать на вход предыдущее и новое значение SINR на тактах $n-1$ и $n$ и затем выдавать результат на последующих тактах с фиксированным тактовым расстоянием. \
\
Потоки проходят сначала через блок забывания, чтобы повлиять на значение глобального состояния, если ранние данные стоит забыть на какой-то процент. Далее входной блок обрабатывает входные данные и добавляет в глобальное состояние ту часть, которую необходимо запомнить, а затем оба потока объединяются во выходном блоке, который уже и выдаёт три результата: локальное состояние в качестве результата, локальное состояние в качестве данных для следующего звена цепи и глобальное состояние для следующего звена цепи. \
\
Отдельное звено можно расписать по следующим формулам: \
$$ I_n = \sigma(w_{input}(h_{n-1} \cdot f_n)+b_{input}) $$

$$ F_n = \sigma(w_{forget}(h_{n-1} \cdot f_n)+b_{forget}) $$

$$ O_n = \sigma(w_{output}(h_{n-1} \cdot f_n)+b_{output}) $$

$$ \widetilde{C}_n = tanh(w_c(h_{n-1} \cdot f_n)) $$

$$ c_n = F_n \otimes c_{n-1} + I_n \otimes \otimes \widetilde{C}_n $$

$$ h_n = o_n \otimes tanh(c_n) $$
